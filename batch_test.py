#!/usr/bin/env python3
"""
å¤§æ‰¹é‡é¸Ÿç±»è¯†åˆ«ä¼˜åŒ–æµ‹è¯•å·¥å…·
ä¸“æ³¨äºå…³é”®é…ç½®çš„å¿«é€Ÿæ‰¹é‡æµ‹è¯•ï¼Œæ”¯æŒ100+å¼ å›¾åƒ
"""
import os
import sys
import time
import json
import numpy as np
import torch
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from queue import Queue

# å¯¼å…¥åŸå§‹æ¨¡å—
try:
    from SuperBirdId import lazy_load_classifier, lazy_load_bird_info, YOLOBirdDetector
    from ebird_country_filter import eBirdCountryFilter
    from bird_database_manager import BirdDatabaseManager
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

class BatchOptimizationTester:
    def __init__(self, test_images_dir: str = None):
        """
        åˆå§‹åŒ–æ‰¹é‡ä¼˜åŒ–æµ‹è¯•å™¨

        Args:
            test_images_dir: æµ‹è¯•å›¾åƒç›®å½•è·¯å¾„
        """
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.test_images_dir = test_images_dir or self.script_dir

        # æ‡’åŠ è½½ç»„ä»¶ï¼ˆå…¨å±€å…±äº«ï¼‰
        self.model = None
        self.bird_info = None
        self.db_manager = None
        self._lock = threading.Lock()

        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.test_results = []

        # å…³é”®æµ‹è¯•é…ç½®ï¼ˆç²¾ç®€ç‰ˆï¼‰
        self.key_configs = [
            {
                'name': 'åŸå§‹åŸºå‡†',
                'enhancement': 'none',
                'preprocessing': 'original',
                'confidence_threshold': 1.0,
                'description': 'å½“å‰ç³»ç»Ÿçš„åŸºå‡†é…ç½®'
            },
            {
                'name': 'æœ€ä½³ç†è®º',
                'enhancement': 'none',  # æ ¹æ®æµ‹è¯•ç»“æœï¼Œæ— å¢å¼ºæ›´å¥½
                'preprocessing': 'traditional_256_224',
                'confidence_threshold': 5.0,  # ä¸¥æ ¼é˜ˆå€¼
                'description': 'åŸºäºä¸Šæ¬¡æµ‹è¯•çš„æœ€ä½³é…ç½®'
            },
            {
                'name': 'æ™ºèƒ½è‡ªé€‚åº”',
                'enhancement': 'none',
                'preprocessing': 'smart_adaptive',
                'confidence_threshold': 1.0,
                'description': 'æ™ºèƒ½é¢„å¤„ç†æ–¹æ³•'
            },
            {
                'name': 'é€Ÿåº¦ä¼˜å…ˆ',
                'enhancement': 'none',
                'preprocessing': 'direct_224',
                'confidence_threshold': 1.0,
                'description': 'æœ€å¿«é€Ÿåº¦é…ç½®'
            },
            {
                'name': 'é™é¥±å’Œåº¦+ä¼ ç»Ÿ',
                'enhancement': 'desaturate',
                'preprocessing': 'traditional_256_224',
                'confidence_threshold': 5.0,
                'description': 'ä¸Šæ¬¡æµ‹è¯•ä¸­æœ€é«˜ç½®ä¿¡åº¦é…ç½®'
            }
        ]

        print(f"ğŸš€ å¤§æ‰¹é‡é¸Ÿç±»è¯†åˆ«ä¼˜åŒ–æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æµ‹è¯•ç›®å½•: {self.test_images_dir}")
        print(f"æµ‹è¯•é…ç½®æ•°é‡: {len(self.key_configs)}")

    def _lazy_load_components(self):
        """çº¿ç¨‹å®‰å…¨çš„æ‡’åŠ è½½ç»„ä»¶"""
        with self._lock:
            if self.model is None:
                print("åŠ è½½AIæ¨¡å‹...")
                self.model = lazy_load_classifier()
                print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

            if self.bird_info is None:
                print("åŠ è½½é¸Ÿç±»æ•°æ®...")
                self.bird_info = lazy_load_bird_info()
                print("âœ“ é¸Ÿç±»æ•°æ®åŠ è½½å®Œæˆ")

            try:
                if self.db_manager is None:
                    self.db_manager = BirdDatabaseManager()
                    print("âœ“ æ•°æ®åº“åŠ è½½å®Œæˆ")
            except:
                self.db_manager = False
                print("âš  æ•°æ®åº“ç®¡ç†å™¨åŠ è½½å¤±è´¥")

    def preprocess_image(self, image: Image.Image, method: str) -> Tuple[torch.Tensor, str]:
        """å›¾åƒé¢„å¤„ç†"""
        width, height = image.size

        if method == 'original':
            # åŸå§‹æ–¹æ³•
            max_dimension = max(width, height)
            if max_dimension < 1000:
                final_image = image.resize((224, 224), Image.LANCZOS)
                method_name = "åŸå§‹-ç›´æ¥224"
            else:
                resized_256 = image.resize((256, 256), Image.LANCZOS)
                left = top = 16
                final_image = resized_256.crop((left, top, left + 224, top + 224))
                method_name = "åŸå§‹-256â†’224"

        elif method == 'direct_224':
            # ç›´æ¥224x224
            final_image = image.resize((224, 224), Image.LANCZOS)
            method_name = "ç›´æ¥224"

        elif method == 'traditional_256_224':
            # ä¼ ç»Ÿ256â†’224
            resized_256 = image.resize((256, 256), Image.LANCZOS)
            left = top = 16
            final_image = resized_256.crop((left, top, left + 224, top + 224))
            method_name = "ä¼ ç»Ÿ256â†’224"

        elif method == 'smart_adaptive':
            # æ™ºèƒ½è‡ªé€‚åº”
            aspect_ratio = width / height
            if 0.8 <= aspect_ratio <= 1.2:
                final_image = image.resize((224, 224), Image.LANCZOS)
                method_name = "æ™ºèƒ½-ç›´æ¥"
            elif aspect_ratio > 1.2:
                new_width = int(224 * aspect_ratio)
                resized = image.resize((new_width, 224), Image.LANCZOS)
                left = (new_width - 224) // 2
                final_image = resized.crop((left, 0, left + 224, 224))
                method_name = "æ™ºèƒ½-å®½å›¾è£å‰ª"
            else:
                new_height = int(224 / aspect_ratio)
                resized = image.resize((224, new_height), Image.LANCZOS)
                top = (new_height - 224) // 2
                final_image = resized.crop((0, top, 224, top + 224))
                method_name = "æ™ºèƒ½-é«˜å›¾è£å‰ª"
        else:
            # é»˜è®¤ç›´æ¥è°ƒæ•´
            final_image = image.resize((224, 224), Image.LANCZOS)
            method_name = "é»˜è®¤ç›´æ¥"

        return self._image_to_tensor(final_image), method_name

    def apply_enhancement(self, image: Image.Image, method: str) -> Image.Image:
        """åº”ç”¨å›¾åƒå¢å¼º"""
        if method == "unsharp_mask":
            return image.filter(ImageFilter.UnsharpMask())
        elif method == "contrast_edge":
            enhancer = ImageEnhance.Brightness(image)
            enhanced = enhancer.enhance(1.2)
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.3)
            return enhanced.filter(ImageFilter.EDGE_ENHANCE)
        elif method == "desaturate":
            enhancer = ImageEnhance.Color(image)
            return enhancer.enhance(0.5)
        else:
            return image

    def _image_to_tensor(self, image: Image.Image) -> torch.Tensor:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡"""
        img_array = np.array(image)
        bgr_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

        # ImageNetæ ‡å‡†åŒ– (BGRæ ¼å¼)
        mean = np.array([0.406, 0.456, 0.485])
        std = np.array([0.225, 0.224, 0.229])

        normalized_array = (bgr_array / 255.0 - mean) / std
        input_tensor = torch.from_numpy(normalized_array).permute(2, 0, 1).unsqueeze(0).float()

        return input_tensor

    def run_inference(self, input_tensor: torch.Tensor) -> Tuple[torch.Tensor, float]:
        """è¿è¡Œæ¨¡å‹æ¨ç†"""
        self._lazy_load_components()

        start_time = time.time()
        with torch.no_grad():
            output = self.model(input_tensor)
        inference_time = time.time() - start_time

        probabilities = torch.nn.functional.softmax(output[0], dim=0)
        return probabilities, inference_time

    def extract_results(self, probabilities: torch.Tensor, confidence_threshold: float = 1.0,
                       top_k: int = 3) -> List[Dict]:
        """æå–è¯†åˆ«ç»“æœ"""
        self._lazy_load_components()

        results = []
        k = min(len(probabilities), len(self.bird_info), 100)
        all_probs, all_catid = torch.topk(probabilities, k)

        count = 0
        for i in range(all_probs.size(0)):
            if count >= top_k:
                break

            class_id = all_catid[i].item()
            confidence = all_probs[i].item() * 100

            if confidence < confidence_threshold:
                continue

            try:
                if class_id < len(self.bird_info) and len(self.bird_info[class_id]) >= 2:
                    bird_name_cn = self.bird_info[class_id][0]
                    bird_name_en = self.bird_info[class_id][1]

                    # å°è¯•è·å–eBirdä»£ç 
                    ebird_code = None
                    if self.db_manager and self.db_manager is not False:
                        ebird_code = self.db_manager.get_ebird_code_by_english_name(bird_name_en)

                    results.append({
                        'class_id': class_id,
                        'confidence': confidence,
                        'chinese_name': bird_name_cn,
                        'english_name': bird_name_en,
                        'ebird_code': ebird_code,
                        'rank': count + 1
                    })
                    count += 1
            except (IndexError, TypeError):
                continue

        return results

    def test_single_image(self, image_path: str) -> Dict:
        """æµ‹è¯•å•å¼ å›¾åƒçš„æ‰€æœ‰å…³é”®é…ç½®"""
        image_name = os.path.basename(image_path)

        try:
            original_image = Image.open(image_path).convert('RGB')
            image_size = original_image.size
        except Exception as e:
            return {
                'image_path': image_path,
                'image_name': image_name,
                'error': f"å›¾åƒåŠ è½½å¤±è´¥: {e}",
                'tests': {}
            }

        test_result = {
            'image_path': image_path,
            'image_name': image_name,
            'image_size': image_size,
            'tests': {}
        }

        # æµ‹è¯•æ¯ä¸ªå…³é”®é…ç½®
        for config in self.key_configs:
            config_name = config['name']

            try:
                # åº”ç”¨å¢å¼º
                enhanced_image = self.apply_enhancement(original_image, config['enhancement'])

                # é¢„å¤„ç†
                input_tensor, method_desc = self.preprocess_image(enhanced_image, config['preprocessing'])

                # æ¨ç†
                probabilities, inference_time = self.run_inference(input_tensor)

                # æå–ç»“æœ
                results = self.extract_results(probabilities, config['confidence_threshold'], top_k=3)
                max_confidence = probabilities.max().item() * 100

                test_result['tests'][config_name] = {
                    'config': config,
                    'method_desc': method_desc,
                    'inference_time': inference_time,
                    'max_confidence': max_confidence,
                    'results_count': len(results),
                    'results': results,
                    'top_confidence': results[0]['confidence'] if results else 0,
                    'top_result': results[0] if results else None
                }

            except Exception as e:
                test_result['tests'][config_name] = {
                    'config': config,
                    'error': str(e)
                }

        return test_result

    def run_batch_test(self, max_images: int = 100, num_threads: int = 4) -> List[Dict]:
        """æ‰¹é‡æµ‹è¯•å¤šå¼ å›¾åƒ"""
        # æœç´¢æµ‹è¯•å›¾åƒ
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tiff", "*.JPG", "*.JPEG"]
        test_images = []

        for pattern in image_patterns:
            test_images.extend(Path(self.test_images_dir).glob(pattern))
            test_images.extend(Path(self.test_images_dir).glob(f"**/{pattern}"))

        test_images = list(set(test_images))  # å»é‡

        if not test_images:
            print(f"âŒ åœ¨ {self.test_images_dir} ä¸­æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
            return []

        # é™åˆ¶å›¾åƒæ•°é‡
        if len(test_images) > max_images:
            test_images = test_images[:max_images]

        print(f"ğŸ¯ å¼€å§‹æ‰¹é‡æµ‹è¯• {len(test_images)} å¼ å›¾åƒ...")
        print(f"ğŸ“‹ æµ‹è¯•é…ç½®: {len(self.key_configs)} ä¸ª")
        print(f"ğŸ”§ é¢„è®¡æ€»æµ‹è¯•æ¬¡æ•°: {len(test_images) * len(self.key_configs)}")
        print(f"ğŸš€ ä½¿ç”¨ {num_threads} ä¸ªçº¿ç¨‹å¹¶è¡Œå¤„ç†")

        # é¢„åŠ è½½æ¨¡å‹ï¼ˆé¿å…çº¿ç¨‹ç«äº‰ï¼‰
        self._lazy_load_components()

        start_time = time.time()
        completed_tests = []

        # ä½¿ç”¨è¿›åº¦é˜Ÿåˆ—
        progress_queue = Queue()

        def update_progress():
            completed = 0
            while completed < len(test_images):
                try:
                    progress_queue.get(timeout=1)
                    completed += 1
                    if completed % 10 == 0 or completed == len(test_images):
                        elapsed = time.time() - start_time
                        rate = completed / elapsed if elapsed > 0 else 0
                        eta = (len(test_images) - completed) / rate if rate > 0 else 0
                        print(f"è¿›åº¦: {completed}/{len(test_images)} ({completed/len(test_images)*100:.1f}%) "
                              f"é€Ÿåº¦: {rate:.1f} å›¾/ç§’ é¢„è®¡å‰©ä½™: {eta:.1f}ç§’")
                except:
                    continue

        # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
        import threading
        progress_thread = threading.Thread(target=update_progress)
        progress_thread.daemon = True
        progress_thread.start()

        # å¹¶è¡Œå¤„ç†å›¾åƒ
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            future_to_image = {
                executor.submit(self.test_single_image, str(image_path)): image_path
                for image_path in test_images
            }

            for future in as_completed(future_to_image):
                image_path = future_to_image[future]
                try:
                    result = future.result()
                    completed_tests.append(result)
                    progress_queue.put(1)
                except Exception as e:
                    print(f"âŒ å¤„ç† {image_path} æ—¶å‡ºé”™: {e}")
                    progress_queue.put(1)

        total_time = time.time() - start_time
        print(f"\nâœ… æ‰¹é‡æµ‹è¯•å®Œæˆ!")
        print(f"æ€»æ—¶é—´: {total_time:.2f}ç§’")
        print(f"å¹³å‡é€Ÿåº¦: {len(test_images)/total_time:.2f} å›¾/ç§’")

        self.test_results = completed_tests
        return completed_tests

    def analyze_results(self) -> Dict:
        """åˆ†ææ‰¹é‡æµ‹è¯•ç»“æœ"""
        if not self.test_results:
            return {}

        print(f"\nğŸ“Š åˆ†æ {len(self.test_results)} å¼ å›¾åƒçš„æµ‹è¯•ç»“æœ...")

        # æ”¶é›†æ‰€æœ‰æˆåŠŸçš„æµ‹è¯•æ•°æ®
        all_test_data = []
        failed_tests = 0

        for result in self.test_results:
            image_name = result['image_name']

            for config_name, test_data in result.get('tests', {}).items():
                if 'error' in test_data:
                    failed_tests += 1
                    continue

                if test_data.get('results_count', 0) > 0:
                    all_test_data.append({
                        'image': image_name,
                        'config': config_name,
                        'top_confidence': test_data['top_confidence'],
                        'max_confidence': test_data['max_confidence'],
                        'inference_time': test_data['inference_time'],
                        'results_count': test_data['results_count'],
                        'top_result': test_data.get('top_result', {}).get('chinese_name', 'Unknown')
                    })

        if not all_test_data:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•æ•°æ®")
            return {}

        # è½¬æ¢ä¸ºDataFrameè¿›è¡Œåˆ†æ
        df = pd.DataFrame(all_test_data)

        # æŒ‰é…ç½®åˆ†ç»„åˆ†æ - ä½¿ç”¨ç®€åŒ–çš„ç»Ÿè®¡æ–¹æ³•
        config_stats = {}
        for config_name in df['config'].unique():
            config_data = df[df['config'] == config_name]
            config_stats[config_name] = {
                'avg_confidence': config_data['top_confidence'].mean(),
                'std_confidence': config_data['top_confidence'].std(),
                'min_confidence': config_data['top_confidence'].min(),
                'max_confidence': config_data['top_confidence'].max(),
                'count': len(config_data),
                'avg_time': config_data['inference_time'].mean(),
                'std_time': config_data['inference_time'].std(),
                'min_time': config_data['inference_time'].min(),
                'max_time': config_data['inference_time'].max()
            }

        # æ‰¾å‡ºæœ€ä½³é…ç½®
        best_avg_confidence = df.groupby('config')['top_confidence'].mean().idxmax()
        best_max_confidence = df.loc[df['top_confidence'].idxmax()]
        fastest_config = df.groupby('config')['inference_time'].mean().idxmin()

        analysis = {
            'summary': {
                'total_images': len(self.test_results),
                'successful_tests': len(all_test_data),
                'failed_tests': failed_tests,
                'success_rate': len(all_test_data) / (len(all_test_data) + failed_tests) * 100 if (len(all_test_data) + failed_tests) > 0 else 0
            },
            'config_performance': config_stats,
            'best_configs': {
                'best_avg_confidence': {
                    'config': best_avg_confidence,
                    'avg_confidence': df.groupby('config')['top_confidence'].mean()[best_avg_confidence]
                },
                'best_max_confidence': {
                    'config': best_max_confidence['config'],
                    'confidence': best_max_confidence['top_confidence'],
                    'image': best_max_confidence['image']
                },
                'fastest': {
                    'config': fastest_config,
                    'avg_time': df.groupby('config')['inference_time'].mean()[fastest_config]
                }
            }
        }

        return analysis

    def generate_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
        analysis = self.analyze_results()

        if not analysis:
            print("âŒ æ— æ³•ç”ŸæˆæŠ¥å‘Šï¼Œæ²¡æœ‰æœ‰æ•ˆæ•°æ®")
            return

        print(f"\n{'='*80}")
        print("ğŸ¯ å¤§æ‰¹é‡é¸Ÿç±»è¯†åˆ«ä¼˜åŒ–æµ‹è¯•æŠ¥å‘Š")
        print(f"{'='*80}")

        # æµ‹è¯•æ‘˜è¦
        summary = analysis['summary']
        print(f"\nğŸ“‹ æµ‹è¯•æ‘˜è¦:")
        print(f"  æµ‹è¯•å›¾åƒæ€»æ•°: {summary['total_images']}")
        print(f"  æˆåŠŸæµ‹è¯•æ¬¡æ•°: {summary['successful_tests']}")
        print(f"  å¤±è´¥æµ‹è¯•æ¬¡æ•°: {summary['failed_tests']}")
        print(f"  æˆåŠŸç‡: {summary['success_rate']:.1f}%")

        # é…ç½®æ€§èƒ½å¯¹æ¯”
        print(f"\nğŸ† é…ç½®æ€§èƒ½æ’è¡Œ:")
        best = analysis['best_configs']

        print(f"  1ï¸âƒ£ å¹³å‡ç½®ä¿¡åº¦æœ€é«˜: {best['best_avg_confidence']['config']}")
        print(f"     å¹³å‡ç½®ä¿¡åº¦: {best['best_avg_confidence']['avg_confidence']:.2f}%")

        print(f"  2ï¸âƒ£ å•æ¬¡æœ€é«˜ç½®ä¿¡åº¦: {best['best_max_confidence']['config']}")
        print(f"     æœ€é«˜ç½®ä¿¡åº¦: {best['best_max_confidence']['confidence']:.2f}%")
        print(f"     å›¾åƒ: {best['best_max_confidence']['image']}")

        print(f"  3ï¸âƒ£ é€Ÿåº¦æœ€å¿«: {best['fastest']['config']}")
        print(f"     å¹³å‡æ¨ç†æ—¶é—´: {best['fastest']['avg_time']:.4f}s")

        # è¯¦ç»†ç»Ÿè®¡ - é‡æ–°æ”¶é›†æ•°æ®
        print(f"\nğŸ“Š è¯¦ç»†é…ç½®ç»Ÿè®¡:")

        # é‡æ–°è®¡ç®—æ¯ä¸ªé…ç½®çš„ç»Ÿè®¡æ•°æ®
        for config in self.key_configs:
            config_name = config['name']

            # æ”¶é›†è¯¥é…ç½®çš„æ‰€æœ‰æ•°æ®
            config_results = []
            for result in self.test_results:
                if config_name in result.get('tests', {}):
                    test_data = result['tests'][config_name]
                    if 'error' not in test_data and test_data.get('results_count', 0) > 0:
                        config_results.append({
                            'confidence': test_data['top_confidence'],
                            'time': test_data['inference_time']
                        })

            if config_results:
                confidences = [r['confidence'] for r in config_results]
                times = [r['time'] for r in config_results]

                avg_conf = np.mean(confidences)
                std_conf = np.std(confidences)
                avg_time = np.mean(times)
                test_count = len(config_results)

                print(f"  {config_name}:")
                print(f"    å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.2f}% (Â±{std_conf:.2f})")
                print(f"    å¹³å‡æ¨ç†æ—¶é—´: {avg_time:.4f}s")
                print(f"    æˆåŠŸæµ‹è¯•æ•°: {test_count}")
            else:
                print(f"  {config_name}: æ— æœ‰æ•ˆæ•°æ®")

        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")

        # æ ¹æ®ç»“æœç»™å‡ºå»ºè®®
        best_config_name = best['best_avg_confidence']['config']
        best_config = next(c for c in self.key_configs if c['name'] == best_config_name)

        print(f"  1. æ¨èä½¿ç”¨é…ç½®: {best_config_name}")
        print(f"     - å›¾åƒå¢å¼º: {best_config['enhancement']}")
        print(f"     - é¢„å¤„ç†æ–¹æ³•: {best_config['preprocessing']}")
        print(f"     - ç½®ä¿¡åº¦é˜ˆå€¼: {best_config['confidence_threshold']}")

        if best['fastest']['config'] != best_config_name:
            print(f"  2. å¦‚éœ€æ›´å¿«é€Ÿåº¦ï¼Œå¯è€ƒè™‘: {best['fastest']['config']}")

        # è®¡ç®—é€Ÿåº¦å·®å¼‚
        fastest_time = best['fastest']['avg_time']

        # æ‰¾åˆ°æœ€ä½³é…ç½®çš„å¹³å‡æ—¶é—´
        best_time = None
        for config in self.key_configs:
            if config['name'] == best_config_name:
                config_results = []
                for result in self.test_results:
                    if best_config_name in result.get('tests', {}):
                        test_data = result['tests'][best_config_name]
                        if 'error' not in test_data:
                            config_results.append(test_data['inference_time'])
                if config_results:
                    best_time = np.mean(config_results)
                break

        if best_time and best_time > fastest_time * 1.5:
            print(f"  3. é€Ÿåº¦vså‡†ç¡®æ€§æƒè¡¡: æœ€ä½³é…ç½®æ¯”æœ€å¿«é…ç½®æ…¢ {best_time/fastest_time:.1f}x")

        print(f"\n{'='*80}")

    def save_results(self, output_file: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if output_file is None:
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            output_file = f"batch_test_results_{timestamp}.json"

        output_path = os.path.join(self.script_dir, output_file)

        results_data = {
            'test_config': {
                'key_configs': self.key_configs,
                'test_images_count': len(self.test_results)
            },
            'test_results': self.test_results,
            'analysis': self.analyze_results(),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2, default=str)
            print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
            return output_path
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return None


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SuperBirdID å¤§æ‰¹é‡ä¼˜åŒ–æµ‹è¯•å·¥å…·")
    print("="*50)

    # è·å–æµ‹è¯•ç›®å½•
    test_dir = input("è¯·è¾“å…¥æµ‹è¯•å›¾åƒç›®å½•è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨å½“å‰ç›®å½•): ").strip() or "."

    if not os.path.exists(test_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return

    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = BatchOptimizationTester(test_dir)

    # è·å–æµ‹è¯•å‚æ•°
    try:
        max_images = input("è¯·è¾“å…¥è¦æµ‹è¯•çš„å›¾åƒæ•°é‡ (ç›´æ¥å›è½¦é»˜è®¤100): ").strip()
        max_images = int(max_images) if max_images else 100

        num_threads = input("è¯·è¾“å…¥å¹¶è¡Œçº¿ç¨‹æ•° (ç›´æ¥å›è½¦é»˜è®¤4): ").strip()
        num_threads = int(num_threads) if num_threads else 4
        num_threads = max(1, min(num_threads, 8))  # é™åˆ¶åœ¨1-8ä¹‹é—´

    except ValueError:
        max_images = 100
        num_threads = 4
        print("ä½¿ç”¨é»˜è®¤å‚æ•°: 100å¼ å›¾åƒ, 4ä¸ªçº¿ç¨‹")

    # è¿è¡Œæ‰¹é‡æµ‹è¯•
    print(f"\nå¼€å§‹æµ‹è¯•æœ€å¤š {max_images} å¼ å›¾åƒï¼Œä½¿ç”¨ {num_threads} ä¸ªçº¿ç¨‹...")

    results = tester.run_batch_test(max_images=max_images, num_threads=num_threads)

    if not results:
        print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
        return

    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    tester.generate_report()

    # ä¿å­˜ç»“æœ
    save_choice = input("\næ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶? (y/n): ").strip().lower()
    if save_choice == 'y':
        tester.save_results()

    print(f"\nğŸ‰ æ‰¹é‡æµ‹è¯•å®Œæˆ! å…±å¤„ç† {len(results)} å¼ å›¾åƒ")


if __name__ == "__main__":
    main()