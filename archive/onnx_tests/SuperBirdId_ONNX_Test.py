import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import json
import cv2
import csv
import os
import time

# æ£€æŸ¥å¹¶å®‰è£…onnxruntime
try:
    import onnxruntime as ort
    print("âœ… ONNX Runtime available")
except ImportError:
    print("âŒ ONNX Runtime not found. Please install it:")
    print("pip install onnxruntime")
    exit()

# --- è·å–è„šæœ¬æ‰€åœ¨ç›®å½• ---
script_dir = os.path.dirname(os.path.abspath(__file__))

# --- åœ°ç†åŒºåŸŸè¯†åˆ«é…ç½® ---
GEOGRAPHIC_REGIONS = {
    'Australia': ['australian', 'australasian', 'new zealand'],
    'Africa': ['african', 'south african'],
    'Europe': ['european', 'eurasian', 'scandinavian', 'caucasian'],
    'Asia': ['asian', 'indian', 'siberian', 'himalayan', 'chinese', 'ryukyu', 'oriental'],
    'North_America': ['american', 'canadian', 'north american'],
    'South_America': ['brazilian', 'patagonian', 'south american', 'west indian'],
    'Pacific': ['pacific'],
    'Arctic': ['arctic']
}

# --- æ¨¡å‹è·¯å¾„ ---
ONNX_MODEL_PATH = os.path.join(script_dir, 'classify_bird_11144.onnx')
PYTORCH_MODEL_PATH = os.path.join(script_dir, 'birdid2024.pt')
BIRD_INFO_PATH = os.path.join(script_dir, 'birdinfo.json')
ENDEMIC_PATH = os.path.join(script_dir, 'endemic.json')
LABELMAP_PATH = os.path.join(script_dir, 'labelmap.csv')

try:
    # åŠ è½½ONNXæ¨¡å‹
    if os.path.exists(ONNX_MODEL_PATH):
        onnx_session = ort.InferenceSession(ONNX_MODEL_PATH)
        
        # è·å–æ‰€æœ‰è¾“å…¥è¾“å‡ºä¿¡æ¯
        inputs = onnx_session.get_inputs()
        outputs = onnx_session.get_outputs()
        
        print(f"âœ… ONNX model loaded successfully")
        print(f"ğŸ“Š æ¨¡å‹æ¶æ„è¯¦æƒ…:")
        
        for i, input_info in enumerate(inputs):
            print(f"   è¾“å…¥{i}: name='{input_info.name}', shape={input_info.shape}, type={input_info.type}")
        
        for i, output_info in enumerate(outputs):
            print(f"   è¾“å‡º{i}: name='{output_info.name}', shape={output_info.shape}, type={output_info.type}")
        
        input_name = inputs[0].name
        output_name = outputs[0].name
        input_shape = inputs[0].shape
        
    else:
        print(f"âŒ ONNX model not found at {ONNX_MODEL_PATH}")
        exit()

    # åŠ è½½PyTorchæ¨¡å‹ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    try:
        import torch
        if os.path.exists(PYTORCH_MODEL_PATH):
            pytorch_model = torch.jit.load(PYTORCH_MODEL_PATH)
            pytorch_model.eval()
            print("âœ… PyTorch model loaded for comparison")
        else:
            pytorch_model = None
            print("âš ï¸ PyTorch model not found, comparison disabled")
    except ImportError:
        pytorch_model = None
        print("âš ï¸ PyTorch not available, comparison disabled")

    # åŠ è½½å…¶ä»–æ•°æ®æ–‡ä»¶
    with open(BIRD_INFO_PATH, 'r') as f:
        bird_info = json.load(f)
    print("âœ… Bird info loaded")

    with open(ENDEMIC_PATH, 'r') as f:
        endemic_info = json.load(f)
    print("âœ… Endemic info loaded")
    
    # åŠ è½½labelmap.csv
    labelmap_data = {}
    if os.path.exists(LABELMAP_PATH):
        with open(LABELMAP_PATH, 'r', encoding='utf-8') as f:
            csv_reader = csv.reader(f)
            for row in csv_reader:
                if len(row) >= 2:
                    try:
                        class_id = int(row[0])
                        name = row[1]
                        labelmap_data[class_id] = name
                    except ValueError:
                        continue
        print(f"âœ… Label map loaded: {len(labelmap_data)} entries")

except Exception as e:
    print(f"âŒ Error loading files: {e}")
    exit()

def get_bird_region(species_name):
    """æ ¹æ®é¸Ÿç±»åç§°æ¨æ–­åœ°ç†åŒºåŸŸ"""
    if not species_name:
        return 'Unknown'
    
    species_lower = species_name.lower()
    
    for region, keywords in GEOGRAPHIC_REGIONS.items():
        for keyword in keywords:
            if keyword in species_lower:
                return region
    
    return 'Unknown'

def calculate_regional_confidence_boost(species_name, user_region=None):
    """è®¡ç®—åœ°ç†åŒºåŸŸç½®ä¿¡åº¦è°ƒæ•´ç³»æ•°"""
    if not user_region or not species_name:
        return 1.0
    
    bird_region = get_bird_region(species_name)
    
    if bird_region == user_region:
        return 1.5  # æœ¬åŒºåŸŸç‰©ç§ç½®ä¿¡åº¦æå‡50%
    elif bird_region != 'Unknown':
        return 0.8  # å…¶ä»–åŒºåŸŸç‰©ç§ç½®ä¿¡åº¦é™ä½20%
    else:
        return 1.0  # æœªçŸ¥åŒºåŸŸç‰©ç§ä¸è°ƒæ•´

def apply_enhancement(image, method="unsharp_mask"):
    """åº”ç”¨æœ€ä½³å›¾åƒå¢å¼ºæ–¹æ³•"""
    if method == "unsharp_mask":
        return image.filter(ImageFilter.UnsharpMask())
    elif method == "contrast_edge":
        enhancer = ImageEnhance.Brightness(image)
        enhanced = enhancer.enhance(1.2)
        enhancer = ImageEnhance.Contrast(enhanced)
        enhanced = enhancer.enhance(1.3)
        return enhanced.filter(ImageFilter.EDGE_ENHANCE)
    elif method == "desaturate":
        enhancer = ImageEnhance.Color(image)
        return enhancer.enhance(0.5)
    else:
        return image

def preprocess_image_rgb(image, target_size=300):
    """RGBæ ¼å¼é¢„å¤„ç†ï¼ˆå¯èƒ½é€‚ç”¨äºONNXæ¨¡å‹ï¼‰"""
    # åº”ç”¨æœ€ä½³å¢å¼º
    enhanced_image = apply_enhancement(image, "unsharp_mask")
    
    # è°ƒæ•´å°ºå¯¸
    resize_size = max(320, target_size + 20)
    resized_image = enhanced_image.resize((resize_size, resize_size), Image.LANCZOS)
    
    left = (resize_size - target_size) // 2
    top = (resize_size - target_size) // 2
    final_image = resized_image.crop((left, top, left + target_size, top + target_size))
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ (ä¿æŒRGBæ ¼å¼)
    img_array = np.array(final_image)
    
    # ImageNetæ ‡å‡†åŒ– (RGBæ ¼å¼)
    mean = np.array([0.485, 0.456, 0.406])  # RGB: R, G, B
    std = np.array([0.229, 0.224, 0.225])   # RGB: R, G, B
    
    normalized_array = (img_array / 255.0 - mean) / std
    
    return normalized_array

def preprocess_image_simple(image, target_size=300):
    """ç®€å•é¢„å¤„ç†ï¼ˆåªåšresizeå’Œå½’ä¸€åŒ–ï¼‰"""
    # ç®€å•resize
    resized_image = image.resize((target_size, target_size), Image.LANCZOS)
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    img_array = np.array(resized_image)
    
    # ç®€å•å½’ä¸€åŒ–åˆ°[0,1]
    normalized_array = img_array / 255.0
    
    return normalized_array

def preprocess_image(image, target_size=300, for_pytorch=False, method="bgr"):
    """é¢„å¤„ç†å›¾åƒ - æ”¯æŒå¤šç§æ–¹æ³•"""
    if for_pytorch:
        # PyTorchä½¿ç”¨BGRæ–¹æ³•
        target_size = 224
        resize_size = 256
        
        enhanced_image = apply_enhancement(image, "unsharp_mask")
        resized_image = enhanced_image.resize((resize_size, resize_size), Image.LANCZOS)
        
        left = (resize_size - target_size) // 2
        top = (resize_size - target_size) // 2
        final_image = resized_image.crop((left, top, left + target_size, top + target_size))
        
        img_array = np.array(final_image)
        bgr_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        
        mean = np.array([0.406, 0.456, 0.485])  # BGR
        std = np.array([0.225, 0.224, 0.229])   # BGR
        
        normalized_array = (bgr_array / 255.0 - mean) / std
        return normalized_array
    else:
        # ONNXæ¨¡å‹å°è¯•ä¸åŒæ–¹æ³•
        if method == "rgb":
            return preprocess_image_rgb(image, target_size)
        elif method == "simple":
            return preprocess_image_simple(image, target_size)
        else:  # "bgr"
            enhanced_image = apply_enhancement(image, "unsharp_mask")
            resize_size = max(320, target_size + 20)
            resized_image = enhanced_image.resize((resize_size, resize_size), Image.LANCZOS)
            
            left = (resize_size - target_size) // 2
            top = (resize_size - target_size) // 2
            final_image = resized_image.crop((left, top, left + target_size, top + target_size))
            
            img_array = np.array(final_image)
            bgr_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            
            mean = np.array([0.406, 0.456, 0.485])  # BGR
            std = np.array([0.225, 0.224, 0.229])   # BGR
            
            normalized_array = (bgr_array / 255.0 - mean) / std
            return normalized_array

def run_onnx_inference(session, input_name, preprocessed_image):
    """è¿è¡ŒONNXæ¨ç†"""
    # æ·»åŠ batchç»´åº¦å¹¶è½¬æ¢ä¸ºfloat32
    input_tensor = np.expand_dims(preprocessed_image.transpose(2, 0, 1), axis=0).astype(np.float32)
    
    start_time = time.time()
    outputs = session.run(None, {input_name: input_tensor})
    inference_time = time.time() - start_time
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    print(f"ğŸ” ONNXæ¨¡å‹è¾“å‡ºå½¢çŠ¶: {outputs[0].shape}")
    
    return outputs[0], inference_time

def run_pytorch_inference(model, preprocessed_image):
    """è¿è¡ŒPyTorchæ¨ç†"""
    if model is None:
        return None, 0
    
    import torch
    input_tensor = torch.from_numpy(preprocessed_image).permute(2, 0, 1).unsqueeze(0).float()
    
    start_time = time.time()
    with torch.no_grad():
        output = model(input_tensor)
    inference_time = time.time() - start_time
    
    return output[0].numpy(), inference_time

def softmax(x):
    """è®¡ç®—softmax"""
    exp_x = np.exp(x - np.max(x))
    return exp_x / np.sum(exp_x)

def process_results(logits, bird_data, user_region=None, model_name="Model"):
    """å¤„ç†è¯†åˆ«ç»“æœ"""
    # ç¡®ä¿logitsæ˜¯1ç»´æ•°ç»„
    if len(logits.shape) > 1:
        logits = logits.flatten()
    
    probabilities = softmax(logits)
    print(f"ğŸ” {model_name} è¾“å‡ºç±»åˆ«æ•°: {len(probabilities)}, bird_dataé•¿åº¦: {len(bird_data)}")
    
    # è°ƒè¯•ä¿¡æ¯ï¼šæ£€æŸ¥è¾“å‡ºå€¼èŒƒå›´
    max_prob = np.max(probabilities) * 100
    min_prob = np.min(probabilities) * 100
    mean_prob = np.mean(probabilities) * 100
    print(f"ğŸ” {model_name} ç½®ä¿¡åº¦èŒƒå›´: æœ€å¤§={max_prob:.4f}%, æœ€å°={min_prob:.4f}%, å¹³å‡={mean_prob:.4f}%")
    
    # æ˜¾ç¤ºå‰5ä¸ªæœ€é«˜ç½®ä¿¡åº¦
    top_5_indices = np.argsort(probabilities)[::-1][:5]
    print(f"ğŸ” {model_name} Top5ç½®ä¿¡åº¦:")
    for i, idx in enumerate(top_5_indices):
        print(f"   {i+1}. ç±»åˆ«{idx}: {probabilities[idx]*100:.4f}%")
    
    # è·å–topç»“æœï¼Œä½†è¦ç¡®ä¿ä¸è¶…å‡ºbird_dataèŒƒå›´
    max_classes = min(len(probabilities), len(bird_data))
    top_indices = np.argsort(probabilities[:max_classes])[::-1][:1000]  # åªå–æœ‰æ•ˆèŒƒå›´å†…çš„ç±»åˆ«
    
    candidates = []
    
    for idx in top_indices:
        raw_confidence = probabilities[idx] * 100
        
        if raw_confidence < 0.5:
            continue
        
        try:
            # åŒé‡æ£€æŸ¥ç´¢å¼•æœ‰æ•ˆæ€§
            if idx < len(bird_data) and idx < len(probabilities) and len(bird_data[idx]) >= 2:
                bird_name_cn = bird_data[idx][0]
                bird_name_en = bird_data[idx][1]
                name = f"{bird_name_cn} ({bird_name_en})"
                
                # åº”ç”¨åœ°ç†åŒºåŸŸç½®ä¿¡åº¦è°ƒæ•´
                region_boost = calculate_regional_confidence_boost(bird_name_en, user_region)
                adjusted_confidence = raw_confidence * region_boost
                
                # è·å–é¸Ÿç±»åŒºåŸŸä¿¡æ¯
                bird_region = get_bird_region(bird_name_en)
                region_info = f" [åŒºåŸŸ: {bird_region}]" if bird_region != 'Unknown' else ""
                boost_info = f" [è°ƒæ•´: {region_boost:.1f}x]" if region_boost != 1.0 else ""
                
                candidates.append({
                    'class_id': idx,
                    'raw_confidence': raw_confidence,
                    'adjusted_confidence': adjusted_confidence,
                    'name': name,
                    'region': bird_region,
                    'boost': region_boost,
                    'display_info': region_info + boost_info
                })
            else:
                # å¦‚æœç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè·³è¿‡
                if idx >= len(bird_data):
                    print(f"âš ï¸ è·³è¿‡è¶…å‡ºèŒƒå›´çš„ç±»åˆ«ç´¢å¼•: {idx} (æœ€å¤§: {len(bird_data)-1})")
        except (IndexError, TypeError) as e:
            print(f"âš ï¸ å¤„ç†ç±»åˆ« {idx} æ—¶å‡ºé”™: {e}")
            pass
    
    # æŒ‰è°ƒæ•´åç½®ä¿¡åº¦æ’åº
    candidates.sort(key=lambda x: x['adjusted_confidence'], reverse=True)
    
    results = []
    for candidate in candidates[:5]:
        if candidate['adjusted_confidence'] >= 1.0:
            results.append(
                f"  ğŸ”¹ {candidate['adjusted_confidence']:.2f}% | {candidate['name']}{candidate['display_info']}"
            )
    
    return results, candidates

def run_model_comparison(image_path, user_region=None):
    """è¿è¡Œæ¨¡å‹å¯¹æ¯”æµ‹è¯•"""
    try:
        # åŠ è½½å›¾åƒ
        original_image = Image.open(image_path).convert("RGB")
        print(f"ğŸ“· åŠ è½½å›¾åƒ: {image_path}")
        
        # ä¸ºä¸åŒæ¨¡å‹é¢„å¤„ç†å›¾åƒ
        pytorch_preprocessed = preprocess_image(original_image, for_pytorch=True)  # 224x224
        
        # å°è¯•ONNXçš„å¤šç§é¢„å¤„ç†æ–¹æ³•
        preprocessing_methods = [
            ("BGR+ImageNetæ ‡å‡†åŒ–", "bgr"),
            ("RGB+ImageNetæ ‡å‡†åŒ–", "rgb"), 
            ("ç®€å•å½’ä¸€åŒ–", "simple")
        ]
        
        print("\n" + "="*80)
        print("ğŸš€ ONNX vs PyTorch æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
        print("="*80)
        
        if user_region:
            print(f"ğŸ“ ç›®æ ‡åŒºåŸŸ: {user_region}")
            print(f"ğŸ“‹ è°ƒæ•´è§„åˆ™: {user_region}åœ°åŒºç‰©ç§ +50%, å…¶ä»–åœ°åŒºç‰©ç§ -20%")
        
        # ONNXæ¨ç† - æµ‹è¯•å¤šç§é¢„å¤„ç†æ–¹æ³•
        best_onnx_results = []
        best_onnx_candidates = []
        best_method_name = ""
        best_confidence = 0
        
        for method_name, method_key in preprocessing_methods:
            print(f"\nğŸ”¥ ONNXæ¨¡å‹æ¨ç†ä¸­... (300x300, {method_name})")
            
            onnx_preprocessed = preprocess_image(original_image, target_size=300, for_pytorch=False, method=method_key)
            onnx_logits, onnx_time = run_onnx_inference(onnx_session, input_name, onnx_preprocessed)
            onnx_results, onnx_candidates = process_results(onnx_logits, bird_info, user_region, f"ONNX-{method_name}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆç»“æœ
            if onnx_candidates and onnx_candidates[0]['adjusted_confidence'] > best_confidence:
                best_confidence = onnx_candidates[0]['adjusted_confidence']
                best_onnx_results = onnx_results
                best_onnx_candidates = onnx_candidates
                best_method_name = method_name
            
            print(f"   ç»“æœæ•°é‡: {len(onnx_results)}")
            if onnx_candidates:
                print(f"   æœ€é«˜ç½®ä¿¡åº¦: {onnx_candidates[0]['adjusted_confidence']:.2f}%")
        
        # ä½¿ç”¨æœ€ä½³ONNXç»“æœè¿›è¡Œæœ€ç»ˆå¯¹æ¯”
        onnx_results = best_onnx_results
        onnx_candidates = best_onnx_candidates
        
        # PyTorchæ¨ç†
        pytorch_results = []
        pytorch_candidates = []
        pytorch_time = 0
        
        if pytorch_model is not None:
            print(f"ğŸ”¥ PyTorchæ¨¡å‹æ¨ç†ä¸­... (224x224)")
            pytorch_logits, pytorch_time = run_pytorch_inference(pytorch_model, pytorch_preprocessed)
            pytorch_results, pytorch_candidates = process_results(pytorch_logits, bird_info, user_region, "PyTorch")
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š ONNXæ¨¡å‹æœ€ä½³ç»“æœ (æ–¹æ³•: {best_method_name}):")
        if onnx_results:
            for result in onnx_results:
                print(result)
        else:
            print("  - æ‰€æœ‰é¢„å¤„ç†æ–¹æ³•éƒ½æ— æ³•è·å¾—æ»¡è¶³æ¡ä»¶çš„è¯†åˆ«ç»“æœ")
        
        if pytorch_model is not None:
            print(f"\nğŸ“Š PyTorchæ¨¡å‹ç»“æœ (æ¨ç†æ—¶é—´: {pytorch_time:.3f}s):")
            if pytorch_results:
                for result in pytorch_results:
                    print(result)
            else:
                print("  - æ— æ»¡è¶³æ¡ä»¶çš„è¯†åˆ«ç»“æœ")
            
            # æ€§èƒ½å¯¹æ¯”
            print(f"\nâš¡ æ€§èƒ½å¯¹æ¯”:")
            print(f"  ONNXæ¨ç†æ—¶é—´:    {onnx_time:.3f}s")
            print(f"  PyTorchæ¨ç†æ—¶é—´: {pytorch_time:.3f}s")
            if pytorch_time > 0:
                speedup = pytorch_time / onnx_time
                print(f"  ONNXåŠ é€Ÿæ¯”:      {speedup:.2f}x")
            
            # ç»“æœä¸€è‡´æ€§æ£€æŸ¥
            if onnx_candidates and pytorch_candidates:
                onnx_top = onnx_candidates[0]['name']
                pytorch_top = pytorch_candidates[0]['name']
                if onnx_top == pytorch_top:
                    print(f"  âœ… ä¸¤æ¨¡å‹è¯†åˆ«ç»“æœä¸€è‡´: {onnx_top}")
                else:
                    print(f"  âš ï¸ ä¸¤æ¨¡å‹è¯†åˆ«ç»“æœä¸åŒ:")
                    print(f"    ONNX:    {onnx_top}")
                    print(f"    PyTorch: {pytorch_top}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

# --- ä¸»ç¨‹åº ---
if __name__ == "__main__":
    # è·å–å›¾ç‰‡è·¯å¾„
    image_path = input("è¯·è¾“å…¥å›¾ç‰‡æ–‡ä»¶çš„å®Œæ•´è·¯å¾„: ")
    if not os.path.exists(image_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        exit()
    
    # è·å–ç”¨æˆ·æ‰€åœ¨åœ°ç†åŒºåŸŸ
    print("\nå¯é€‰åœ°ç†åŒºåŸŸ:")
    regions = list(GEOGRAPHIC_REGIONS.keys()) + ['None']
    for i, region in enumerate(regions, 1):
        print(f"{i}. {region}")
    
    try:
        region_choice = input("\nè¯·é€‰æ‹©æ‚¨æ‰€åœ¨çš„åœ°ç†åŒºåŸŸ (è¾“å…¥æ•°å­—ï¼Œæˆ–ç›´æ¥å›è½¦è·³è¿‡): ").strip()
        if region_choice and region_choice.isdigit():
            choice_idx = int(region_choice) - 1
            if 0 <= choice_idx < len(regions) - 1:  # æ’é™¤ 'None'
                user_region = regions[choice_idx]
                print(f"å·²é€‰æ‹©åŒºåŸŸ: {user_region}")
            else:
                user_region = None
                print("æœªé€‰æ‹©ç‰¹å®šåŒºåŸŸï¼Œå°†è¿›è¡Œå…¨çƒæ¨¡å¼æµ‹è¯•")
        else:
            user_region = None
            print("æœªé€‰æ‹©ç‰¹å®šåŒºåŸŸï¼Œå°†è¿›è¡Œå…¨çƒæ¨¡å¼æµ‹è¯•")
    except:
        user_region = None
        print("è¾“å…¥æ— æ•ˆï¼Œå°†è¿›è¡Œå…¨çƒæ¨¡å¼æµ‹è¯•")
    
    # è¿è¡Œå¯¹æ¯”æµ‹è¯•
    run_model_comparison(image_path, user_region)