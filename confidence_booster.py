#!/usr/bin/env python3
"""
ç½®ä¿¡åº¦æå‡å·¥å…·
é’ˆå¯¹ä½ç½®ä¿¡åº¦é—®é¢˜çš„å¤šç­–ç•¥è§£å†³æ–¹æ¡ˆ
"""
import torch
import numpy as np
from PIL import Image, ImageEnhance, ImageFilter
import cv2
from typing import List, Tuple, Dict, Optional
import time

# å¯¼å…¥åŸå§‹æ¨¡å—
from SuperBirdId import lazy_load_classifier, lazy_load_bird_info, lazy_load_database

# ============================================
# ç­–ç•¥1: æµ‹è¯•æ—¶å¢å¼º (Test-Time Augmentation)
# ============================================
class TTABooster:
    """æµ‹è¯•æ—¶å¢å¼º - é€šè¿‡å¤šæ¬¡æ¨ç†å¹³å‡æé«˜ç½®ä¿¡åº¦"""

    def __init__(self):
        self.augmentations = [
            ('åŸå§‹', self.no_aug),
            ('æ°´å¹³ç¿»è½¬', self.horizontal_flip),
            ('è½»å¾®æ—‹è½¬+5åº¦', lambda img: self.rotate(img, 5)),
            ('è½»å¾®æ—‹è½¬-5åº¦', lambda img: self.rotate(img, -5)),
            ('äº®åº¦å¢å¼º', self.brightness_up),
            ('å¯¹æ¯”åº¦å¢å¼º', self.contrast_up),
            ('é”åŒ–', self.sharpen),
            ('ä¸­å¿ƒè£å‰ª', self.center_crop),
        ]

    def no_aug(self, img):
        return img

    def horizontal_flip(self, img):
        return img.transpose(Image.FLIP_LEFT_RIGHT)

    def rotate(self, img, degrees):
        return img.rotate(degrees, resample=Image.BICUBIC, expand=False)

    def brightness_up(self, img):
        enhancer = ImageEnhance.Brightness(img)
        return enhancer.enhance(1.15)  # æé«˜15%äº®åº¦

    def contrast_up(self, img):
        enhancer = ImageEnhance.Contrast(img)
        return enhancer.enhance(1.2)  # æé«˜20%å¯¹æ¯”åº¦

    def sharpen(self, img):
        enhancer = ImageEnhance.Sharpness(img)
        return enhancer.enhance(1.5)  # æé«˜50%é”åº¦

    def center_crop(self, img):
        """ä¸­å¿ƒè£å‰ª90% - å»é™¤è¾¹ç¼˜å¹²æ‰°"""
        w, h = img.size
        crop_w, crop_h = int(w * 0.9), int(h * 0.9)
        left = (w - crop_w) // 2
        top = (h - crop_h) // 2
        return img.crop((left, top, left + crop_w, top + crop_h))

    def predict_with_tta(self, image: Image.Image, model, preprocess_func,
                         top_k: int = 5) -> Dict:
        """
        ä½¿ç”¨TTAè¿›è¡Œé¢„æµ‹

        Args:
            image: PILå›¾åƒ
            model: PyTorchæ¨¡å‹
            preprocess_func: é¢„å¤„ç†å‡½æ•°
            top_k: è¿”å›å‰kä¸ªç»“æœ

        Returns:
            å¢å¼ºåçš„é¢„æµ‹ç»“æœ
        """
        all_predictions = []

        print(f"ğŸ”„ å¼€å§‹TTA (æµ‹è¯•æ—¶å¢å¼º): {len(self.augmentations)}ç§å˜æ¢...")

        for aug_name, aug_func in self.augmentations:
            # åº”ç”¨å¢å¼º
            aug_image = aug_func(image)

            # é¢„å¤„ç†
            processed = preprocess_func(aug_image)

            # æ¨ç†
            with torch.no_grad():
                output = model(processed)

            probs = torch.nn.functional.softmax(output[0], dim=0)
            all_predictions.append(probs.numpy())

        # å¹³å‡æ‰€æœ‰é¢„æµ‹
        avg_probs = np.mean(all_predictions, axis=0)
        std_probs = np.std(all_predictions, axis=0)

        # è·å–top-kç»“æœ
        top_indices = np.argsort(avg_probs)[-top_k:][::-1]

        results = []
        for idx in top_indices:
            results.append({
                'class_id': int(idx),
                'avg_confidence': float(avg_probs[idx] * 100),
                'std': float(std_probs[idx] * 100),
                'min': float((avg_probs[idx] - std_probs[idx]) * 100),
                'max': float((avg_probs[idx] + std_probs[idx]) * 100),
            })

        print(f"âœ“ TTAå®Œæˆï¼Œå¹³å‡ç½®ä¿¡åº¦æå‡: "
              f"{results[0]['avg_confidence']:.2f}% (Â±{results[0]['std']:.2f}%)")

        return {
            'method': 'TTA-8ç§å¢å¼º',
            'results': results,
            'all_predictions': all_predictions
        }


# ============================================
# ç­–ç•¥2: å¤šå°ºåº¦èåˆ
# ============================================
class MultiScaleBooster:
    """å¤šå°ºåº¦é¢„æµ‹èåˆ"""

    def __init__(self):
        self.scales = [
            (224, 'æ ‡å‡†224'),
            (256, 'å¤§å°ºå¯¸256'),
            (192, 'å°å°ºå¯¸192'),
            (288, 'è¶…å¤§å°ºå¯¸288'),
        ]

    def predict_multiscale(self, image: Image.Image, model, top_k: int = 5) -> Dict:
        """å¤šå°ºåº¦é¢„æµ‹"""
        all_predictions = []

        print(f"ğŸ“ å¼€å§‹å¤šå°ºåº¦é¢„æµ‹: {len(self.scales)}ç§å°ºå¯¸...")

        for size, name in self.scales:
            # è°ƒæ•´å°ºå¯¸
            resized = image.resize((size, size), Image.LANCZOS)

            # æ ‡å‡†åŒ–
            img_array = np.array(resized)
            bgr_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

            mean = np.array([0.406, 0.456, 0.485])
            std = np.array([0.225, 0.224, 0.229])

            normalized = (bgr_array / 255.0 - mean) / std
            tensor = torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0).float()

            # æ¨ç†
            with torch.no_grad():
                output = model(tensor)

            probs = torch.nn.functional.softmax(output[0], dim=0).numpy()
            all_predictions.append(probs)

        # åŠ æƒå¹³å‡ (å¤§å°ºå¯¸æƒé‡æ›´é«˜)
        weights = np.array([1.0, 1.2, 0.8, 1.3])
        weights = weights / weights.sum()

        weighted_avg = np.average(all_predictions, axis=0, weights=weights)

        # è·å–top-k
        top_indices = np.argsort(weighted_avg)[-top_k:][::-1]

        results = []
        for idx in top_indices:
            results.append({
                'class_id': int(idx),
                'confidence': float(weighted_avg[idx] * 100)
            })

        print(f"âœ“ å¤šå°ºåº¦å®Œæˆï¼Œæœ€é«˜ç½®ä¿¡åº¦: {results[0]['confidence']:.2f}%")

        return {
            'method': 'å¤šå°ºåº¦èåˆ',
            'results': results
        }


# ============================================
# ç­–ç•¥3: æ™ºèƒ½YOLOè£å‰ªä¼˜åŒ–
# ============================================
class SmartCropBooster:
    """æ™ºèƒ½è£å‰ªç­–ç•¥"""

    def __init__(self, yolo_model_path='yolo11x.pt'):
        try:
            from ultralytics import YOLO
            self.yolo = YOLO(yolo_model_path)
            self.available = True
        except:
            self.available = False
            print("âš  YOLOä¸å¯ç”¨ï¼Œè·³è¿‡æ™ºèƒ½è£å‰ª")

    def get_best_crop(self, image_path: str) -> Optional[Image.Image]:
        """è·å–æœ€ä½³è£å‰ªåŒºåŸŸ"""
        if not self.available:
            return None

        results = self.yolo(image_path, conf=0.15)  # é™ä½é˜ˆå€¼æ•è·æ›´å¤šå€™é€‰

        bird_detections = []
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    class_id = int(box.cls[0].cpu().numpy())
                    if class_id == 14:  # é¸Ÿç±»
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = box.conf[0].cpu().numpy()
                        area = (x2 - x1) * (y2 - y1)

                        bird_detections.append({
                            'bbox': [int(x1), int(y1), int(x2), int(y2)],
                            'confidence': float(confidence),
                            'area': float(area)
                        })

        if not bird_detections:
            return None

        # é€‰æ‹©æœ€å¤§ä¸”ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹
        best = max(bird_detections,
                   key=lambda x: x['confidence'] * (x['area'] ** 0.5))

        image = Image.open(image_path).convert('RGB')
        x1, y1, x2, y2 = best['bbox']

        # æ™ºèƒ½è¾¹è·ï¼šé¢ç§¯è¶Šå°ï¼Œè¾¹è·è¶Šå¤§
        area_ratio = best['area'] / (image.width * image.height)
        padding = int(max(50, 200 * (1 - area_ratio)))

        x1 = max(0, x1 - padding)
        y1 = max(0, y1 - padding)
        x2 = min(image.width, x2 + padding)
        y2 = min(image.height, y2 + padding)

        cropped = image.crop((x1, y1, x2, y2))

        print(f"âœ‚ï¸  æ™ºèƒ½è£å‰ª: {cropped.size}, è¾¹è·={padding}px, "
              f"YOLOç½®ä¿¡åº¦={best['confidence']:.2f}")

        return cropped


# ============================================
# ç­–ç•¥4: æ¸©åº¦ç¼©æ”¾æ ¡å‡†
# ============================================
class TemperatureScaling:
    """æ¸©åº¦ç¼©æ”¾ - æ ¡å‡†æ¨¡å‹è¾“å‡ºæ¦‚ç‡"""

    def __init__(self, temperature: float = 1.5):
        """
        Args:
            temperature: æ¸©åº¦å‚æ•°
                - T > 1: è½¯åŒ–åˆ†å¸ƒï¼Œæé«˜ä½æ¦‚ç‡ç±»çš„ç›¸å¯¹ç½®ä¿¡åº¦
                - T < 1: é”åŒ–åˆ†å¸ƒï¼Œå¼ºåŒ–é«˜æ¦‚ç‡ç±»
                - T = 1: ä¸å˜
        """
        self.temperature = temperature

    def apply(self, logits: torch.Tensor) -> torch.Tensor:
        """åº”ç”¨æ¸©åº¦ç¼©æ”¾"""
        scaled_logits = logits / self.temperature
        return torch.nn.functional.softmax(scaled_logits, dim=0)

    def calibrate(self, model, image_tensor: torch.Tensor,
                  temperatures: List[float] = [0.8, 1.0, 1.2, 1.5, 2.0]) -> Dict:
        """æµ‹è¯•ä¸åŒæ¸©åº¦"""
        with torch.no_grad():
            logits = model(image_tensor)[0]

        results = {}
        for T in temperatures:
            scaled_probs = self.apply(logits * 1.0, T)  # å…‹éš†é¿å…ä¿®æ”¹
            max_prob = scaled_probs.max().item()
            max_idx = scaled_probs.argmax().item()

            results[T] = {
                'max_confidence': max_prob * 100,
                'class_id': max_idx,
                'probabilities': scaled_probs
            }

        return results


# ============================================
# ä¸»å‡½æ•°ï¼šç»¼åˆæå‡ç­–ç•¥
# ============================================
def boost_confidence(image_path: str,
                     strategy: str = 'all',
                     ebird_filter_set: Optional[set] = None) -> Dict:
    """
    ç»¼åˆç½®ä¿¡åº¦æå‡

    Args:
        image_path: å›¾åƒè·¯å¾„
        strategy: 'tta' | 'multiscale' | 'crop' | 'all'
        ebird_filter_set: eBirdè¿‡æ»¤ç‰©ç§é›†åˆ

    Returns:
        æå‡åçš„è¯†åˆ«ç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"ğŸš€ ç½®ä¿¡åº¦æå‡å·¥å…·")
    print(f"{'='*60}")
    print(f"å›¾åƒ: {image_path}")
    print(f"ç­–ç•¥: {strategy}")

    # åŠ è½½æ¨¡å‹å’Œæ•°æ®
    model = lazy_load_classifier()
    bird_info = lazy_load_bird_info()
    db_manager = lazy_load_database()

    # åŠ è½½å›¾åƒ
    original_image = Image.open(image_path).convert('RGB')

    # ç­–ç•¥1: æ™ºèƒ½è£å‰ª (å¦‚æœéœ€è¦)
    if strategy in ['crop', 'all']:
        crop_booster = SmartCropBooster()
        cropped = crop_booster.get_best_crop(image_path)
        if cropped:
            original_image = cropped

    # é¢„å¤„ç†å‡½æ•°
    def preprocess(img):
        # ä½¿ç”¨ä¼ ç»Ÿ256â†’224æ–¹æ³•
        resized = img.resize((256, 256), Image.LANCZOS)
        cropped = resized.crop((16, 16, 240, 240))

        img_array = np.array(cropped)
        bgr_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

        mean = np.array([0.406, 0.456, 0.485])
        std = np.array([0.225, 0.224, 0.229])

        normalized = (bgr_array / 255.0 - mean) / std
        return torch.from_numpy(normalized).permute(2, 0, 1).unsqueeze(0).float()

    all_results = {}

    # ç­–ç•¥2: TTA
    if strategy in ['tta', 'all']:
        tta_booster = TTABooster()
        tta_result = tta_booster.predict_with_tta(original_image, model, preprocess)
        all_results['tta'] = tta_result

    # ç­–ç•¥3: å¤šå°ºåº¦
    if strategy in ['multiscale', 'all']:
        ms_booster = MultiScaleBooster()
        ms_result = ms_booster.predict_multiscale(original_image, model)
        all_results['multiscale'] = ms_result

    # èåˆæ‰€æœ‰ç»“æœ
    final_results = merge_results(all_results, bird_info, db_manager, ebird_filter_set)

    # æ‰“å°æœ€ç»ˆç»“æœ
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æœ€ç»ˆè¯†åˆ«ç»“æœ (æå‡å)")
    print(f"{'='*60}")

    for i, result in enumerate(final_results[:5], 1):
        ebird_tag = "ğŸŒ" if result.get('ebird_match') else ""
        print(f"{i}. {result['name']}")
        print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}% {ebird_tag}")
        if 'confidence_range' in result:
            print(f"   èŒƒå›´: {result['confidence_range']}")

    return final_results


def merge_results(all_results: Dict, bird_info: List, db_manager,
                  ebird_filter: Optional[set] = None) -> List[Dict]:
    """èåˆå¤šç§ç­–ç•¥çš„ç»“æœ"""

    # æ”¶é›†æ‰€æœ‰å€™é€‰
    class_scores = {}

    # TTAç»“æœ (æƒé‡: 1.5)
    if 'tta' in all_results:
        for res in all_results['tta']['results']:
            cid = res['class_id']
            class_scores[cid] = class_scores.get(cid, 0) + res['avg_confidence'] * 1.5

    # å¤šå°ºåº¦ç»“æœ (æƒé‡: 1.2)
    if 'multiscale' in all_results:
        for res in all_results['multiscale']['results']:
            cid = res['class_id']
            class_scores[cid] = class_scores.get(cid, 0) + res['confidence'] * 1.2

    # æ’åº
    sorted_classes = sorted(class_scores.items(), key=lambda x: x[1], reverse=True)

    # æ„å»ºæœ€ç»ˆç»“æœ
    final = []
    for class_id, score in sorted_classes[:10]:
        if class_id < len(bird_info) and len(bird_info[class_id]) >= 2:
            cn_name = bird_info[class_id][0]
            en_name = bird_info[class_id][1]

            result = {
                'class_id': class_id,
                'confidence': score,
                'chinese_name': cn_name,
                'english_name': en_name,
                'name': f"{cn_name} ({en_name})"
            }

            # eBirdåŒ¹é…æ£€æŸ¥
            if db_manager and ebird_filter:
                ebird_code = db_manager.get_ebird_code_by_english_name(en_name)
                if ebird_code and ebird_code in ebird_filter:
                    result['ebird_match'] = True
                    result['confidence'] *= 1.3  # é¢å¤–30%æå‡

            final.append(result)

    # é‡æ–°æ’åº
    final.sort(key=lambda x: x['confidence'], reverse=True)

    return final


# ============================================
# æµ‹è¯•å…¥å£
# ============================================
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("ç”¨æ³•: python confidence_booster.py <å›¾ç‰‡è·¯å¾„> [ç­–ç•¥]")
        print("ç­–ç•¥é€‰é¡¹: tta, multiscale, crop, all (é»˜è®¤)")
        sys.exit(1)

    image_path = sys.argv[1]
    strategy = sys.argv[2] if len(sys.argv) > 2 else 'all'

    results = boost_confidence(image_path, strategy)
