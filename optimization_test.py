#!/usr/bin/env python3
"""
é¸Ÿç±»è¯†åˆ«ä¼˜åŒ–æµ‹è¯•å·¥å…·
å¯¹æ¯”å„ç§ä¼˜åŒ–æ–¹æ¡ˆçš„è¯†åˆ«æ•ˆæœï¼Œé‡åŒ–æ”¹è¿›æ•ˆæœ
"""
import os
import sys
import time
import json
import numpy as np
import torch
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
import matplotlib.pyplot as plt
from pathlib import Path

# å¯¼å…¥åŸå§‹æ¨¡å—
try:
    from SuperBirdId import lazy_load_classifier, lazy_load_bird_info, YOLOBirdDetector
    from ebird_country_filter import eBirdCountryFilter
    from bird_database_manager import BirdDatabaseManager
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

class BirdIDOptimizationTester:
    def __init__(self, test_images_dir: str = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–æµ‹è¯•å™¨

        Args:
            test_images_dir: æµ‹è¯•å›¾åƒç›®å½•è·¯å¾„
        """
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.test_images_dir = test_images_dir or self.script_dir

        # æ‡’åŠ è½½ç»„ä»¶
        self.model = None
        self.bird_info = None
        self.yolo_detector = None
        self.db_manager = None

        # æµ‹è¯•ç»“æœå­˜å‚¨
        self.test_results = []

        # æµ‹è¯•é…ç½®
        self.test_configs = {
            'preprocessing': {
                'original': 'åŸå§‹æ–¹æ³•',
                'direct_224': 'ç›´æ¥224x224',
                'traditional_256_224': 'ä¼ ç»Ÿ256â†’224',
                'smart_adaptive': 'æ™ºèƒ½è‡ªé€‚åº”'
            },
            'confidence_thresholds': {
                'strict': 5.0,     # ä¸¥æ ¼é˜ˆå€¼ 5%
                'normal': 1.0,     # æ­£å¸¸é˜ˆå€¼ 1%
                'loose': 0.1,      # å®½æ¾é˜ˆå€¼ 0.1%
                'dynamic': 'auto'  # åŠ¨æ€é˜ˆå€¼
            },
            'yolo_confidence': {
                'conservative': 0.5,  # ä¿å®ˆ 50%
                'normal': 0.25,       # æ­£å¸¸ 25%
                'aggressive': 0.1     # æ¿€è¿› 10%
            },
            'enhancement_methods': {
                'none': 'æ— å¢å¼º',
                'unsharp_mask': 'UnsharpMaskå¢å¼º',
                'contrast_edge': 'å¯¹æ¯”åº¦+è¾¹ç¼˜å¢å¼º',
                'desaturate': 'é™é¥±å’Œåº¦'
            }
        }

        print(f"ğŸ”¬ é¸Ÿç±»è¯†åˆ«ä¼˜åŒ–æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æµ‹è¯•ç›®å½•: {self.test_images_dir}")

    def _lazy_load_components(self):
        """æ‡’åŠ è½½æ‰€éœ€ç»„ä»¶"""
        if self.model is None:
            print("åŠ è½½AIæ¨¡å‹...")
            self.model = lazy_load_classifier()

        if self.bird_info is None:
            print("åŠ è½½é¸Ÿç±»æ•°æ®...")
            self.bird_info = lazy_load_bird_info()

        if self.yolo_detector is None:
            print("åˆå§‹åŒ–YOLOæ£€æµ‹å™¨...")
            self.yolo_detector = YOLOBirdDetector()

        try:
            if self.db_manager is None:
                self.db_manager = BirdDatabaseManager()
        except:
            print("âš  æ•°æ®åº“ç®¡ç†å™¨åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨JSONæ•°æ®")

    def preprocess_image_original(self, image: Image.Image) -> Tuple[np.ndarray, str]:
        """åŸå§‹é¢„å¤„ç†æ–¹æ³•"""
        # ç›´æ¥ä½¿ç”¨smart_resizeçš„é€»è¾‘
        width, height = image.size
        max_dimension = max(width, height)

        if max_dimension < 1000:
            final_image = image.resize((224, 224), Image.LANCZOS)
            method_name = "åŸå§‹-ç›´æ¥è°ƒæ•´(å°å›¾åƒ)"
        else:
            # ä¼ ç»Ÿ256â†’224æ–¹æ³•
            resized_256 = image.resize((256, 256), Image.LANCZOS)
            left = (256 - 224) // 2
            top = (256 - 224) // 2
            final_image = resized_256.crop((left, top, left + 224, top + 224))
            method_name = "åŸå§‹-ä¼ ç»Ÿæ–¹æ³•(å¤§å›¾åƒ)"

        return self._image_to_tensor(final_image), method_name

    def preprocess_image_direct_224(self, image: Image.Image) -> Tuple[np.ndarray, str]:
        """ç›´æ¥224x224é¢„å¤„ç†"""
        final_image = image.resize((224, 224), Image.LANCZOS)
        return self._image_to_tensor(final_image), "ç›´æ¥224x224"

    def preprocess_image_traditional(self, image: Image.Image) -> Tuple[np.ndarray, str]:
        """ä¼ ç»Ÿ256â†’224é¢„å¤„ç†"""
        resized_256 = image.resize((256, 256), Image.LANCZOS)
        left = (256 - 224) // 2
        top = (256 - 224) // 2
        final_image = resized_256.crop((left, top, left + 224, top + 224))
        return self._image_to_tensor(final_image), "ä¼ ç»Ÿ256â†’224"

    def preprocess_image_smart_adaptive(self, image: Image.Image) -> Tuple[np.ndarray, str]:
        """æ™ºèƒ½è‡ªé€‚åº”é¢„å¤„ç†"""
        width, height = image.size
        aspect_ratio = width / height

        # æ ¹æ®å®½é«˜æ¯”é€‰æ‹©æœ€ä½³é¢„å¤„ç†ç­–ç•¥
        if 0.8 <= aspect_ratio <= 1.2:  # æ¥è¿‘æ­£æ–¹å½¢
            final_image = image.resize((224, 224), Image.LANCZOS)
            method_name = "æ™ºèƒ½-ç›´æ¥è°ƒæ•´(æ­£æ–¹å½¢)"
        elif aspect_ratio > 1.2:  # å®½å›¾
            # å…ˆè°ƒæ•´åˆ°åˆé€‚é«˜åº¦ï¼Œç„¶åè£å‰ª
            new_width = int(224 * aspect_ratio)
            resized = image.resize((new_width, 224), Image.LANCZOS)
            left = (new_width - 224) // 2
            final_image = resized.crop((left, 0, left + 224, 224))
            method_name = "æ™ºèƒ½-å®½å›¾è£å‰ª"
        else:  # é«˜å›¾
            # å…ˆè°ƒæ•´åˆ°åˆé€‚å®½åº¦ï¼Œç„¶åè£å‰ª
            new_height = int(224 / aspect_ratio)
            resized = image.resize((224, new_height), Image.LANCZOS)
            top = (new_height - 224) // 2
            final_image = resized.crop((0, top, 224, top + 224))
            method_name = "æ™ºèƒ½-é«˜å›¾è£å‰ª"

        return self._image_to_tensor(final_image), method_name

    def _image_to_tensor(self, image: Image.Image) -> np.ndarray:
        """å°†PILå›¾åƒè½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥å¼ é‡"""
        img_array = np.array(image)

        # è½¬æ¢ä¸ºBGRé€šé“é¡ºåºï¼ˆä¿æŒä¸åŸä»£ç ä¸€è‡´ï¼‰
        bgr_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)

        # ImageNetæ ‡å‡†åŒ– (BGRæ ¼å¼)
        mean = np.array([0.406, 0.456, 0.485])  # BGR: B, G, R
        std = np.array([0.225, 0.224, 0.229])   # BGR: B, G, R

        normalized_array = (bgr_array / 255.0 - mean) / std
        input_tensor = torch.from_numpy(normalized_array).permute(2, 0, 1).unsqueeze(0).float()

        return input_tensor

    def apply_enhancement(self, image: Image.Image, method: str) -> Image.Image:
        """åº”ç”¨å›¾åƒå¢å¼º"""
        if method == "unsharp_mask":
            return image.filter(ImageFilter.UnsharpMask())
        elif method == "contrast_edge":
            enhancer = ImageEnhance.Brightness(image)
            enhanced = enhancer.enhance(1.2)
            enhancer = ImageEnhance.Contrast(enhanced)
            enhanced = enhancer.enhance(1.3)
            return enhanced.filter(ImageFilter.EDGE_ENHANCE)
        elif method == "desaturate":
            enhancer = ImageEnhance.Color(image)
            return enhancer.enhance(0.5)
        else:
            return image

    def run_inference(self, input_tensor: torch.Tensor) -> Tuple[torch.Tensor, float]:
        """è¿è¡Œæ¨¡å‹æ¨ç†"""
        self._lazy_load_components()

        start_time = time.time()
        with torch.no_grad():
            output = self.model(input_tensor)
        inference_time = time.time() - start_time

        probabilities = torch.nn.functional.softmax(output[0], dim=0)
        return probabilities, inference_time

    def extract_results(self, probabilities: torch.Tensor, confidence_threshold: float = 1.0,
                       top_k: int = 5) -> List[Dict]:
        """æå–è¯†åˆ«ç»“æœ"""
        self._lazy_load_components()

        results = []
        k = min(len(probabilities), len(self.bird_info), 1000)
        all_probs, all_catid = torch.topk(probabilities, k)

        # åŠ¨æ€é˜ˆå€¼è®¡ç®—
        if confidence_threshold == 'auto':
            # è®¡ç®—æ¦‚ç‡åˆ†å¸ƒçš„ç»Ÿè®¡ä¿¡æ¯
            probs_array = probabilities.cpu().numpy()
            mean_prob = np.mean(probs_array)
            std_prob = np.std(probs_array)
            confidence_threshold = max(0.1, (mean_prob + std_prob) * 100)  # åŠ¨æ€é˜ˆå€¼

        count = 0
        for i in range(all_probs.size(0)):
            if count >= top_k:
                break

            class_id = all_catid[i].item()
            confidence = all_probs[i].item() * 100

            if confidence < confidence_threshold:
                continue

            try:
                if class_id < len(self.bird_info) and len(self.bird_info[class_id]) >= 2:
                    bird_name_cn = self.bird_info[class_id][0]
                    bird_name_en = self.bird_info[class_id][1]

                    # å°è¯•è·å–eBirdä»£ç 
                    ebird_code = None
                    if self.db_manager:
                        ebird_code = self.db_manager.get_ebird_code_by_english_name(bird_name_en)

                    results.append({
                        'class_id': class_id,
                        'confidence': confidence,
                        'chinese_name': bird_name_cn,
                        'english_name': bird_name_en,
                        'ebird_code': ebird_code,
                        'rank': count + 1
                    })
                    count += 1
            except (IndexError, TypeError):
                continue

        return results

    def test_single_image_comprehensive(self, image_path: str) -> Dict:
        """å¯¹å•å¼ å›¾åƒè¿›è¡Œå…¨é¢æµ‹è¯•"""
        print(f"\nğŸ” æµ‹è¯•å›¾åƒ: {os.path.basename(image_path)}")

        try:
            original_image = Image.open(image_path).convert('RGB')
            image_size = original_image.size
            print(f"å›¾åƒå°ºå¯¸: {image_size}")
        except Exception as e:
            print(f"âŒ å›¾åƒåŠ è½½å¤±è´¥: {e}")
            return {}

        test_result = {
            'image_path': image_path,
            'image_size': image_size,
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'tests': {}
        }

        # é¢„å¤„ç†æ–¹æ³•æµ‹è¯•
        preprocessing_methods = {
            'original': self.preprocess_image_original,
            'direct_224': self.preprocess_image_direct_224,
            'traditional_256_224': self.preprocess_image_traditional,
            'smart_adaptive': self.preprocess_image_smart_adaptive
        }

        # YOLOæ£€æµ‹æµ‹è¯•ï¼ˆä»…å¯¹å¤§å›¾åƒï¼‰
        yolo_results = {}
        if max(image_size) > 640 and self.yolo_detector and self.yolo_detector.model:
            print("  ğŸ¯ æµ‹è¯•YOLOæ£€æµ‹å‚æ•°...")
            for conf_name, conf_value in self.test_configs['yolo_confidence'].items():
                try:
                    cropped_image, detection_msg = self.yolo_detector.detect_and_crop_bird(
                        image_path, confidence_threshold=conf_value
                    )
                    yolo_results[conf_name] = {
                        'success': cropped_image is not None,
                        'message': detection_msg,
                        'cropped_size': cropped_image.size if cropped_image else None
                    }
                except Exception as e:
                    yolo_results[conf_name] = {
                        'success': False,
                        'message': f"YOLOæ£€æµ‹å¤±è´¥: {e}",
                        'cropped_size': None
                    }

        # å¯¹æ¯ç§å›¾åƒå¢å¼ºæ–¹æ³•è¿›è¡Œæµ‹è¯•
        for enhancement_name, enhancement_desc in self.test_configs['enhancement_methods'].items():
            print(f"  ğŸ¨ æµ‹è¯•å¢å¼ºæ–¹æ³•: {enhancement_desc}")

            # åº”ç”¨å¢å¼º
            if enhancement_name == 'none':
                enhanced_image = original_image
            else:
                enhanced_image = self.apply_enhancement(original_image, enhancement_name)

            # æµ‹è¯•æ¯ç§é¢„å¤„ç†æ–¹æ³•
            for prep_name, prep_func in preprocessing_methods.items():
                print(f"    ğŸ”§ é¢„å¤„ç†: {self.test_configs['preprocessing'][prep_name]}")

                try:
                    # é¢„å¤„ç†
                    input_tensor, method_desc = prep_func(enhanced_image)

                    # æ¨ç†
                    probabilities, inference_time = self.run_inference(input_tensor)

                    # æµ‹è¯•ä¸åŒç½®ä¿¡åº¦é˜ˆå€¼
                    threshold_results = {}
                    for threshold_name, threshold_value in self.test_configs['confidence_thresholds'].items():
                        results = self.extract_results(probabilities, threshold_value, top_k=5)

                        threshold_results[threshold_name] = {
                            'threshold_value': threshold_value,
                            'results_count': len(results),
                            'results': results,
                            'top_confidence': results[0]['confidence'] if results else 0,
                            'top_result': results[0] if results else None
                        }

                    test_key = f"{enhancement_name}_{prep_name}"
                    test_result['tests'][test_key] = {
                        'enhancement': enhancement_desc,
                        'preprocessing': method_desc,
                        'inference_time': inference_time,
                        'max_confidence': probabilities.max().item() * 100,
                        'confidence_thresholds': threshold_results
                    }

                except Exception as e:
                    print(f"    âŒ æµ‹è¯•å¤±è´¥: {e}")
                    test_key = f"{enhancement_name}_{prep_name}"
                    test_result['tests'][test_key] = {
                        'error': str(e),
                        'enhancement': enhancement_desc,
                        'preprocessing': self.test_configs['preprocessing'][prep_name]
                    }

        test_result['yolo_detection'] = yolo_results
        print(f"âœ… å›¾åƒæµ‹è¯•å®Œæˆ: {len(test_result['tests'])} ä¸ªç»„åˆ")

        return test_result

    def run_batch_test(self, image_patterns: List[str] = None) -> List[Dict]:
        """æ‰¹é‡æµ‹è¯•å¤šå¼ å›¾åƒ"""
        if image_patterns is None:
            # é»˜è®¤æœç´¢æµ‹è¯•å›¾åƒ
            image_patterns = [
                "*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tiff"
            ]

        test_images = []
        for pattern in image_patterns:
            test_images.extend(Path(self.test_images_dir).glob(pattern))

        # è·å–ç”¨æˆ·æŒ‡å®šçš„æµ‹è¯•å›¾åƒæ•°é‡
        test_images = list(test_images)

        if len(test_images) > 10:
            print(f"å‘ç° {len(test_images)} å¼ å›¾åƒ")
            max_count = input(f"è¯·è¾“å…¥è¦æµ‹è¯•çš„å›¾åƒæ•°é‡ (ç›´æ¥å›è½¦æµ‹è¯•å‰100å¼ ): ").strip()
            try:
                max_count = int(max_count) if max_count else 100
                max_count = min(max_count, len(test_images))
                test_images = test_images[:max_count]
            except ValueError:
                test_images = test_images[:100]

        if not test_images:
            print(f"âŒ åœ¨ {self.test_images_dir} ä¸­æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
            return []

        print(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯• {len(test_images)} å¼ å›¾åƒ...")

        all_results = []
        for i, image_path in enumerate(test_images, 1):
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•è¿›åº¦: {i}/{len(test_images)}")

            result = self.test_single_image_comprehensive(str(image_path))
            if result:
                all_results.append(result)

        self.test_results = all_results
        return all_results

    def analyze_results(self) -> Dict:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not self.test_results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯åˆ†æ")
            return {}

        print(f"\nğŸ“Š åˆ†æ {len(self.test_results)} å¼ å›¾åƒçš„æµ‹è¯•ç»“æœ...")

        analysis = {
            'summary': {
                'total_images': len(self.test_results),
                'total_tests': 0,
                'successful_tests': 0
            },
            'best_combinations': {},
            'method_performance': {
                'enhancement': {},
                'preprocessing': {},
                'confidence_threshold': {}
            },
            'recommendations': []
        }

        # æ”¶é›†æ‰€æœ‰æµ‹è¯•æ•°æ®
        all_test_data = []

        for result in self.test_results:
            for test_key, test_data in result.get('tests', {}).items():
                if 'error' in test_data:
                    continue

                analysis['summary']['total_tests'] += 1

                enhancement, preprocessing = test_key.split('_', 1)

                for threshold_name, threshold_data in test_data.get('confidence_thresholds', {}).items():
                    if threshold_data['results_count'] > 0:
                        analysis['summary']['successful_tests'] += 1

                        test_record = {
                            'image': os.path.basename(result['image_path']),
                            'enhancement': enhancement,
                            'preprocessing': preprocessing,
                            'threshold': threshold_name,
                            'top_confidence': threshold_data['top_confidence'],
                            'results_count': threshold_data['results_count'],
                            'inference_time': test_data['inference_time'],
                            'max_confidence': test_data['max_confidence']
                        }
                        all_test_data.append(test_record)

        if not all_test_data:
            print("âŒ æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•æ•°æ®")
            return analysis

        # è½¬æ¢ä¸ºDataFrameè¿›è¡Œåˆ†æ
        df = pd.DataFrame(all_test_data)

        # åˆ†ææœ€ä½³ç»„åˆ
        best_by_confidence = df.loc[df['top_confidence'].idxmax()]
        best_by_speed = df.loc[df['inference_time'].idxmin()]

        # ç¨³å®šæ€§åˆ†æï¼ˆä»…åœ¨å¤šå¼ å›¾åƒæ—¶æœ‰æ•ˆï¼‰
        most_stable = None
        if len(self.test_results) > 1:
            best_by_stability = df.groupby(['enhancement', 'preprocessing', 'threshold'])['top_confidence'].agg(['mean', 'std']).reset_index()
            best_by_stability['stability_score'] = best_by_stability['mean'] / (best_by_stability['std'] + 0.1)
            if not best_by_stability['stability_score'].isna().all():
                most_stable = best_by_stability.loc[best_by_stability['stability_score'].idxmax()]

        analysis['best_combinations'] = {
            'highest_confidence': {
                'combination': f"{best_by_confidence['enhancement']}_{best_by_confidence['preprocessing']}_{best_by_confidence['threshold']}",
                'confidence': best_by_confidence['top_confidence'],
                'details': best_by_confidence.to_dict()
            },
            'fastest': {
                'combination': f"{best_by_speed['enhancement']}_{best_by_speed['preprocessing']}_{best_by_speed['threshold']}",
                'time': best_by_speed['inference_time'],
                'details': best_by_speed.to_dict()
            }
        }

        # æ·»åŠ ç¨³å®šæ€§åˆ†æï¼ˆä»…åœ¨å¤šå¼ å›¾åƒæ—¶ï¼‰
        if most_stable is not None:
            analysis['best_combinations']['most_stable'] = {
                'combination': f"{most_stable['enhancement']}_{most_stable['preprocessing']}_{most_stable['threshold']}",
                'stability_score': most_stable['stability_score'],
                'mean_confidence': most_stable['mean'],
                'confidence_std': most_stable['std']
            }

        # æ–¹æ³•æ€§èƒ½ç»Ÿè®¡
        analysis['method_performance']['enhancement'] = df.groupby('enhancement')['top_confidence'].agg(['mean', 'std', 'count']).to_dict('index')
        analysis['method_performance']['preprocessing'] = df.groupby('preprocessing')['top_confidence'].agg(['mean', 'std', 'count']).to_dict('index')
        analysis['method_performance']['confidence_threshold'] = df.groupby('threshold')['top_confidence'].agg(['mean', 'std', 'count']).to_dict('index')

        # ç”Ÿæˆå»ºè®®
        best_enhancement = df.groupby('enhancement')['top_confidence'].mean().idxmax()
        best_preprocessing = df.groupby('preprocessing')['top_confidence'].mean().idxmax()
        best_threshold = df.groupby('threshold')['top_confidence'].mean().idxmax()

        analysis['recommendations'] = [
            f"æœ€ä½³å›¾åƒå¢å¼ºæ–¹æ³•: {self.test_configs['enhancement_methods'].get(best_enhancement, best_enhancement)}",
            f"æœ€ä½³é¢„å¤„ç†æ–¹æ³•: {self.test_configs['preprocessing'].get(best_preprocessing, best_preprocessing)}",
            f"æœ€ä½³ç½®ä¿¡åº¦é˜ˆå€¼: {best_threshold}",
            f"å¹³å‡ç½®ä¿¡åº¦æå‡: {df['top_confidence'].mean():.2f}%",
            f"æ¨ç†æ—¶é—´èŒƒå›´: {df['inference_time'].min():.3f}s - {df['inference_time'].max():.3f}s"
        ]

        return analysis

    def save_results(self, output_file: str = None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if output_file is None:
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            output_file = f"optimization_test_results_{timestamp}.json"

        output_path = os.path.join(self.script_dir, output_file)

        results_data = {
            'test_config': self.test_configs,
            'test_results': self.test_results,
            'analysis': self.analyze_results(),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }

        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results_data, f, ensure_ascii=False, indent=2, default=str)
            print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        analysis = self.analyze_results()

        if not analysis:
            return

        print(f"\n{'='*80}")
        print("ğŸ¯ é¸Ÿç±»è¯†åˆ«ä¼˜åŒ–æµ‹è¯•æŠ¥å‘Š")
        print(f"{'='*80}")

        # æ‘˜è¦
        summary = analysis['summary']
        print(f"\nğŸ“‹ æµ‹è¯•æ‘˜è¦:")
        print(f"  æµ‹è¯•å›¾åƒæ•°é‡: {summary['total_images']}")
        print(f"  æ€»æµ‹è¯•æ¬¡æ•°: {summary['total_tests']}")
        print(f"  æˆåŠŸæµ‹è¯•æ¬¡æ•°: {summary['successful_tests']}")
        print(f"  æˆåŠŸç‡: {summary['successful_tests']/summary['total_tests']*100:.1f}%")

        # æœ€ä½³ç»„åˆ
        best = analysis['best_combinations']
        print(f"\nğŸ† æœ€ä½³ç»„åˆ:")
        print(f"  æœ€é«˜ç½®ä¿¡åº¦ç»„åˆ: {best['highest_confidence']['combination']}")
        print(f"    ç½®ä¿¡åº¦: {best['highest_confidence']['confidence']:.2f}%")
        print(f"  æœ€å¿«ç»„åˆ: {best['fastest']['combination']}")
        print(f"    æ¨ç†æ—¶é—´: {best['fastest']['time']:.3f}s")

        if 'most_stable' in best:
            print(f"  æœ€ç¨³å®šç»„åˆ: {best['most_stable']['combination']}")
            print(f"    ç¨³å®šæ€§å¾—åˆ†: {best['most_stable']['stability_score']:.2f}")
        else:
            print(f"  æœ€ç¨³å®šç»„åˆ: éœ€è¦å¤šå¼ å›¾åƒæµ‹è¯•æ‰èƒ½è®¡ç®—")

        # å»ºè®®
        print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        for i, recommendation in enumerate(analysis['recommendations'], 1):
            print(f"  {i}. {recommendation}")

        print(f"\n{'='*80}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¦ SuperBirdID ä¼˜åŒ–æµ‹è¯•å·¥å…·")
    print("="*50)

    # è·å–æµ‹è¯•ç›®å½•
    test_dir = input("è¯·è¾“å…¥æµ‹è¯•å›¾åƒç›®å½•è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨å½“å‰ç›®å½•): ").strip() or "."

    if not os.path.exists(test_dir):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {test_dir}")
        return

    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = BirdIDOptimizationTester(test_dir)

    print("\né€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. å•å¼ å›¾åƒæµ‹è¯•")
    print("2. æ‰¹é‡å›¾åƒæµ‹è¯•")

    choice = input("è¯·é€‰æ‹© (1-2): ").strip()

    if choice == '1':
        # å•å¼ å›¾åƒæµ‹è¯•
        image_path = input("è¯·è¾“å…¥å›¾åƒæ–‡ä»¶è·¯å¾„: ").strip().strip("'\"")
        if not os.path.exists(image_path):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            return

        result = tester.test_single_image_comprehensive(image_path)
        if result:
            tester.test_results = [result]

    elif choice == '2':
        # æ‰¹é‡æµ‹è¯•
        tester.run_batch_test()

    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return

    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    tester.generate_report()

    # ä¿å­˜ç»“æœ
    save_choice = input("\næ˜¯å¦ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶? (y/n): ").strip().lower()
    if save_choice == 'y':
        tester.save_results()


if __name__ == "__main__":
    main()